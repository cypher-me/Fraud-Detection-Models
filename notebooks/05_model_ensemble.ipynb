{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Ensemble & Hyperparameter Tuning with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data and model predictions\n",
    "y_test = np.load('../models/y_test.npy')\n",
    "\n",
    "# Load individual model predictions (create dummy if files don't exist)\n",
    "try:\n",
    "    gnn_preds = np.load('../models/gnn_test_predictions.npy')\n",
    "except:\n",
    "    gnn_preds = np.random.random(len(y_test)) * 0.1  # Dummy predictions\n",
    "    \n",
    "try:\n",
    "    autoencoder_scores = np.load('../models/autoencoder_test_scores.npy')\n",
    "    autoencoder_preds = np.load('../models/autoencoder_test_predictions.npy')\n",
    "except:\n",
    "    autoencoder_scores = np.random.random(len(y_test)) * 0.1\n",
    "    autoencoder_preds = (autoencoder_scores > 0.05).astype(int)\n",
    "\n",
    "# Create Isolation Forest predictions (simulate streaming results)\n",
    "from sklearn.ensemble import IsolationForest\n",
    "X_test = np.load('../models/X_test.npy')\n",
    "iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "iso_forest.fit(np.load('../models/X_train.npy'))\n",
    "iso_scores = iso_forest.decision_function(X_test)\n",
    "iso_preds = (iso_forest.predict(X_test) == -1).astype(int)\n",
    "\n",
    "print(f\"Test samples: {len(y_test)}\")\n",
    "print(f\"GNN predictions shape: {gnn_preds.shape}\")\n",
    "print(f\"Autoencoder predictions shape: {autoencoder_preds.shape}\")\n",
    "print(f\"Isolation Forest predictions shape: {iso_preds.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual model performance\n",
    "models_performance = {\n",
    "    'GNN': roc_auc_score(y_test, gnn_preds),\n",
    "    'Autoencoder': roc_auc_score(y_test, autoencoder_scores),\n",
    "    'Isolation Forest': roc_auc_score(y_test, -iso_scores)  # Negative because lower scores = more anomalous\n",
    "}\n",
    "\n",
    "print(\"Individual Model Performance (AUC):\")\n",
    "for model, auc in models_performance.items():\n",
    "    print(f\"{model}: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ensemble features\n",
    "# Normalize scores to [0,1] range\n",
    "gnn_norm = (gnn_preds - gnn_preds.min()) / (gnn_preds.max() - gnn_preds.min() + 1e-8)\n",
    "autoencoder_norm = (autoencoder_scores - autoencoder_scores.min()) / (autoencoder_scores.max() - autoencoder_scores.min() + 1e-8)\n",
    "iso_norm = (-iso_scores - (-iso_scores).min()) / ((-iso_scores).max() - (-iso_scores).min() + 1e-8)\n",
    "\n",
    "# Ensemble feature matrix\n",
    "ensemble_features = np.column_stack([\n",
    "    gnn_norm,\n",
    "    autoencoder_norm, \n",
    "    iso_norm,\n",
    "    gnn_preds,\n",
    "    autoencoder_preds,\n",
    "    iso_preds\n",
    "])\n",
    "\n",
    "print(f\"Ensemble features shape: {ensemble_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna hyperparameter optimization\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    model_type = trial.suggest_categorical('model', ['rf', 'lr'])\n",
    "    \n",
    "    if model_type == 'rf':\n",
    "        n_estimators = trial.suggest_int('n_estimators', 50, 200)\n",
    "        max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            random_state=42\n",
    "        )\n",
    "    else:\n",
    "        C = trial.suggest_float('C', 0.01, 10.0, log=True)\n",
    "        model = LogisticRegression(C=C, random_state=42, max_iter=1000)\n",
    "    \n",
    "    # Cross-validation score\n",
    "    cv_scores = cross_val_score(model, ensemble_features, y_test, cv=3, scoring='roc_auc')\n",
    "    return cv_scores.mean()\n",
    "\n",
    "# Run optimization\n",
    "print(\"Starting hyperparameter optimization...\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(f\"Best AUC: {study.best_value:.4f}\")\n",
    "print(f\"Best parameters: {study.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final ensemble model\n",
    "best_params = study.best_params\n",
    "if best_params['model'] == 'rf':\n",
    "    final_model = RandomForestClassifier(\n",
    "        n_estimators=best_params['n_estimators'],\n",
    "        max_depth=best_params['max_depth'],\n",
    "        random_state=42\n",
    "    )\n",
    "else:\n",
    "    final_model = LogisticRegression(\n",
    "        C=best_params['C'],\n",
    "        random_state=42,\n",
    "        max_iter=1000\n",
    "    )\n",
    "\n",
    "# Split data for training and testing ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_ens_train, X_ens_test, y_ens_train, y_ens_test = train_test_split(\n",
    "    ensemble_features, y_test, test_size=0.3, random_state=42, stratify=y_test\n",
    ")\n",
    "\n",
    "final_model.fit(X_ens_train, y_ens_train)\n",
    "ensemble_preds = final_model.predict_proba(X_ens_test)[:, 1]\n",
    "ensemble_auc = roc_auc_score(y_ens_test, ensemble_preds)\n",
    "\n",
    "print(f\"Final Ensemble AUC: {ensemble_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance comparison\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': ['GNN', 'Autoencoder', 'Isolation Forest', 'Ensemble'],\n",
    "    'AUC': [models_performance['GNN'], models_performance['Autoencoder'], \n",
    "            models_performance['Isolation Forest'], ensemble_auc]\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(results_df['Model'], results_df['AUC'], \n",
    "               color=['skyblue', 'lightgreen', 'orange', 'red'])\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.ylabel('AUC Score')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, auc in zip(bars, results_df['AUC']):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f'{auc:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/ensemble_performance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance (if Random Forest)\n",
    "if hasattr(final_model, 'feature_importances_'):\n",
    "    feature_names = ['GNN_norm', 'Autoencoder_norm', 'IsoForest_norm', \n",
    "                    'GNN_pred', 'Autoencoder_pred', 'IsoForest_pred']\n",
    "    \n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': final_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "    plt.title('Ensemble Feature Importance')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../reports/ensemble_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ensemble model\n",
    "with open('../models/ensemble_model.pkl', 'wb') as f:\n",
    "    pickle.dump(final_model, f)\n",
    "\n",
    "with open('../models/ensemble_best_params.pkl', 'wb') as f:\n",
    "    pickle.dump(best_params, f)\n",
    "\n",
    "np.save('../models/ensemble_test_predictions.npy', ensemble_preds)\n",
    "\n",
    "print(\"Ensemble model training completed!\")\n",
    "print(f\"Best ensemble AUC: {ensemble_auc:.4f}\")\n",
    "print(\"Model saved to: ../models/ensemble_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}